version: 1
pruners:
  prune_func1:
    criterion: l1_norm
    prune_type: specified_layer_prune
    ratio: 0.0625
    layers_to_be_pruned: [
            res1_conv2d_1_2,
            res1_conv2d_2_2,
            res1_conv2d_3_2,
            res2_conv2d_1_2,
            res2_conv2d_2_2,
            res2_conv2d_3_2,
            res2_conv2d_4_2,
            res3_conv2d_1_2,
            res3_conv2d_2_2,
            res3_conv2d_3_2,
            res3_conv2d_4_2,
            res3_conv2d_5_2,
            res3_conv2d_6_2,
            res4_conv2d_1_2,
            res4_conv2d_2_2,
            res4_conv2d_3_2,
            ]

lr_schedulers:
  # Learning rate
  - name: warmup_lr
    class: LearningRateWarmupCallback
    warmup_epochs: 5
    verbose: 0
  - name: lr_multiply_1
    class: LearningRateScheduleCallback
    start_epoch: 5
    end_epoch: 30
    multiplier: 1.0
  - name: lr_multiply_0.1
    class: LearningRateScheduleCallback
    start_epoch: 30
    end_epoch: 90
    multiplier: 1e-1
  - name: lr_multiply_0.01
    class: LearningRateScheduleCallback
    start_epoch: 90
    end_epoch: 110
    multiplier: 1e-2
  - name: lr_multiply_0.001
    class: LearningRateScheduleCallback
    start_epoch: 110
    multiplier: 1e-3

prune_schedulers:
  - pruner:
      func_name: prune_func1
    epochs: [50,52,54,56,58,60,62,64]

